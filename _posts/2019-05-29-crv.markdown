---
layout: post
title:  "End-to-End Learned Event- and Image-based Visual Odometry"
date:   2019-05-29 22:21:59 +00:00
image: /images_/ramp_2.png
categories: research
author: "Leo Keselman"
authors: "<strong>Leonid Keselman</strong>, Martial Hebert"
venue: "Computer and Robot Vision Conference"
arxiv: https://arxiv.org/abs/1904.05537
slides: /pdfs/crv19-slides.pdf
code: https://github.com/leonidk/direct_gmm
website: https://leonidk.github.io/direct_gmm/
---

We introduce RAMP-VO, the first end-to-end learned event- and image-based VO system. It leverages novel Recurrent, Asynchronous, and Massively Parallel (RAMP) encoders that are 8Ã— faster and 20% more accurate than existing asynchronous encoders. RAMP-VO further employs a novel pose forecasting technique to predict future poses for initialization. Despite being trained only in simulation, RAMP- VO outperforms image- and event-based methods by 52% and 20%